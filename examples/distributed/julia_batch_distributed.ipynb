{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Julia workloads with nested levels of task parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AzureClusterlessHPC supports running multi-node batch tasks that use Julia's original package for distributed programming. This enables users to call e.g. `pmap` functions in a nested fashion.\n",
    "\n",
    "## Set up\n",
    "\n",
    "To enable multi-node Julia tasks, we need to set the following parameters in our `parameters.json` file:\n",
    "\n",
    "- `\"_POOL_COUNT\"`: Set this parameter to the number of batch pool that you want to use in parallel.\n",
    "\n",
    "- `\"_NODE_COUNT_PER_POOL\"`: Number of nodes per pool\n",
    "\n",
    "- `\"_MPI_RUN\"`: Set to `\"0\"`\n",
    "\n",
    "- `\"_INTER_NODE_CONNECTION\"`: Set to `\"1\"`\n",
    "\n",
    "- `\"_NUM_NODES_PER_TASK\"`: Number of parallel Julia workers per task. This value needs to be equal to or smaller than the number of nodes per pool.\n",
    "\n",
    "- `\"_NUM_PROCS_PER_NODE\"`: Set to `\"1\"`\n",
    "\n",
    "Note than in comparison to running a multi-node MPI task, multi-node distributed tasks have `\"_MPI_RUN\"` set to zero, while `\"_INTER_NODE_CONNECTION\"` must be set to 1. In this combination, the code of each AzureClusterlessHPC task is executed by the runtime via `julia -p $_NUM_NODES_PER_TASK`.\n",
    "\n",
    "We start by setting the environment variables that point to our credentials and our `parameters.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to credentials\n",
    "ENV[\"CREDENTIALS\"] = joinpath(pwd(), \"credentials.json\")\n",
    "\n",
    "# Set path to batch parameters (pool id, VM types, etc.)\n",
    "ENV[\"PARAMETERS\"] = joinpath(pwd(), \"parameters.json\")\n",
    "\n",
    "# Load package\n",
    "using AzureClusterlessHPC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we start our batch pool. If `\"_INTER_NODE_CONNECTION\"` is set to `\"1\"`, AzureClusterlessHPC enables inter-node communication in the batch pool(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created pool 1 of 2 in canadacentral with 4 nodes.\n",
      "Created pool 2 of 2 in canadacentral with 4 nodes.\n"
     ]
    }
   ],
   "source": [
    "# Create pool\n",
    "startup_script = \"pool_startup_script.sh\"\n",
    "create_pool_and_resource_file(startup_script);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Julia jobs with nested levels of parallelization\n",
    "\n",
    "To execute individual Julia tasks in parallel Julia sessions, we first need to load the Distributed.jl package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef using Distributed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a hello_world function that will be executed in parallel by multiple Julia tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef function hello_world(name)\n",
    "    print(\"Hello \", name, \"from \", myid(), \"\\n\")\n",
    "    return \"Goodbye from $name\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define another function called say_hello, which executes the hello_world function in parallel via Julia's (original) pmap function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@batchdef function say_hello(name_lists)\n",
    "    N = length(name_lists)\n",
    "    out = pmap(i -> hello_world(name_lists[i]), 1:N)\n",
    "    return out\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use AzureClusterlessHPC to execute the say_hello function in parallel as a multi-task batch job. Each of the tasks calls the above say_hello function, which each execute an additional parallel pmap function. We now define our list of input arguments, which consists of two individual lists, each with four names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_lists = [[\"Bob\", \"Jane\", \"John\", \"Anne\"],\n",
    "              [\"Mark\", \"Sarah\", \"Max\", \"Emma\"]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now execute the say_hello function twice via AzureClusterlessHPC. Each task receives a list with four names as an input argument and then calls the hello_world function via the pmap function in say_hello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.229663 seconds (3.53 M allocations: 210.794 MiB, 1.34% gc time, 53.39% compilation time)\n"
     ]
    }
   ],
   "source": [
    "# Run say_hello function in parallel via AzureClusterlessHPC\n",
    "bctrl = @batchexec pmap(i -> say_hello(name_lists[i]), 1:2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each say_hello function collects the output from its parallel Julia session. Via the fetch function, we can then collect the output from the two say_hello tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring tasks for 'Completed' state, timeout in 60 minutes ...Creating job [BatchJob_sIld3PxL_1]...\n",
      "Uploading file /home/pwitte/.julia/dev/AzureClusterlessHPC/src/runtime/application-cmd to blob container [azureclusterlesstemp]...\n",
      "Uploading file /home/pwitte/.julia/dev/AzureClusterlessHPC/src/runtime/batch_runtime.jl to blob container [azureclusterlesstemp]...\n",
      "Uploading file packages.dat to container [azureclusterlesstemp]...\n",
      "Uploading file task_1.dat to container [azureclusterlesstemp]...\n",
      "Creating job [BatchJob_sIld3PxL_2]...\n",
      "Uploading file /home/pwitte/.julia/dev/AzureClusterlessHPC/src/runtime/application-cmd to blob container [azureclusterlesstemp]...\n",
      "Uploading file /home/pwitte/.julia/dev/AzureClusterlessHPC/src/runtime/batch_runtime.jl to blob container [azureclusterlesstemp]...\n",
      "Uploading file packages.dat to container [azureclusterlesstemp]...\n",
      "Uploading file task_2.dat to container [azureclusterlesstemp]...\n",
      "..........................................................................................................................................................................\n",
      "Fetch output from task task_2.........\n",
      "Fetch output from task task_1\n",
      "Any[[\"Goodbye from Bob\", \"Goodbye from Jane\", \"Goodbye from John\", \"Goodbye from Anne\"], [\"Goodbye from Mark\", \"Goodbye from Sarah\", \"Goodbye from Max\", \"Goodbye from Emma\"]]"
     ]
    }
   ],
   "source": [
    "# Collect output\n",
    "out = fetch(bctrl)\n",
    "print(out);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, we clean up all consumed Azure resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy!(bctrl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyright\n",
    "\n",
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License (MIT). See LICENSE in the repo root for license information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
